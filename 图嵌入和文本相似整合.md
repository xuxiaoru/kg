要实现**图嵌入相似度召回**和**文本相似度召回**的权重融合，可以按照以下步骤来实现：

### 1. 使用 Node2Vec 生成图嵌入
使用 `Node2Vec` 来生成节点的图嵌入，捕捉图结构信息。

```python
from node2vec import Node2Vec
import networkx as nx

# 创建图对象
G = nx.Graph()
# 添加节点和边 (你的图数据)
G.add_edges_from([(1, 2), (1, 3), (2, 3), (3, 4)])

# 训练 Node2Vec 模型
node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)
model = node2vec.fit(window=10, min_count=1)

# 获取每个节点的嵌入
embeddings = model.wv
```

### 2. 保存图嵌入到向量库
将生成的图嵌入保存到向量库中，比如使用 `Faiss` 进行相似度检索。

```python
import faiss
import numpy as np

# 获取所有节点的嵌入并构建 Faiss 索引
node_ids = list(embeddings.index_to_key)  # 获取节点ID列表
node_vectors = np.array([embeddings[node] for node in node_ids]).astype('float32')

# 建立Faiss索引
index = faiss.IndexFlatL2(64)  # L2 = 欧几里得距离
index.add(node_vectors)

# 保存Faiss索引
faiss.write_index(index, "node2vec_embeddings.index")
```

### 3. 对新数据从向量库做欧几里得距离相似度召回前50
当有新的节点数据时，可以根据其嵌入从向量库中召回最相似的节点。

```python
# 加载Faiss索引
index = faiss.read_index("node2vec_embeddings.index")

# 新节点的嵌入
new_node_embedding = np.array([embeddings['1']]).astype('float32')

# 检索前50个最相似的节点
D_graph, I_graph = index.search(new_node_embedding, 50)
similar_nodes_graph = {node_ids[i]: D_graph[0][idx] for idx, i in enumerate(I_graph[0])}
```

### 4. 文本相似度召回（基于节点描述的语义信息）
对节点的文本描述进行文本相似度召回，可以使用 `Sentence-BERT` 生成语义嵌入。

```python
from sentence_transformers import SentenceTransformer

# 加载Sentence-BERT模型
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# 假设每个节点有一个文本描述
node_descriptions = {
    '1': "This is a description of node 1.",
    '2': "Description for node 2.",
    '3': "Node 3 is about X and Y."
}

# 为每个节点生成文本嵌入
text_embeddings = np.array([model.encode(node_descriptions[node]) for node in node_ids]).astype('float32')

# 创建Faiss索引
text_index = faiss.IndexFlatL2(384)  # 384维度为Sentence-BERT输出的嵌入大小
text_index.add(text_embeddings)

# 新节点的文本描述嵌入
new_node_description = "This node is related to X."
new_text_embedding = np.array([model.encode(new_node_description)]).astype('float32')

# 检索文本相似度前50个节点
D_text, I_text = text_index.search(new_text_embedding, 50)
similar_nodes_text = {node_ids[i]: D_text[0][idx] for idx, i in enumerate(I_text[0])}
```

### 5. 权重融合图嵌入和文本相似度召回结果
最后一步是对图嵌入和文本相似度的召回结果进行加权融合。可以通过设置不同的权重来平衡图结构信息和语义信息。

```python
# 定义权重
alpha = 0.6  # 图嵌入的权重
beta = 0.4   # 文本相似度的权重

# 融合结果
combined_scores = {}
all_node_ids = set(similar_nodes_graph.keys()).union(set(similar_nodes_text.keys()))

for node_id in all_node_ids:
    score_graph = similar_nodes_graph.get(node_id, np.inf)  # 没有值时设为无穷大
    score_text = similar_nodes_text.get(node_id, np.inf)
    
    # 计算加权综合分数
    combined_score = alpha * score_graph + beta * score_text
    combined_scores[node_id] = combined_score

# 排序并取前50个节点
final_result = sorted(combined_scores.items(), key=lambda item: item[1])[:50]
print("Top 50 combined similar nodes:", final_result)
```

### 总结
1. **图嵌入生成**：使用 Node2Vec 生成节点的图嵌入。
2. **向量库保存和召回**：将嵌入保存到 `Faiss` 向量库，使用欧几里得距离进行图嵌入相似度召回。
3. **文本相似度召回**：基于节点描述生成文本嵌入，进行文本相似度召回。
4. **权重融合**：通过加权平均法，将图嵌入和文本相似度的结果综合，输出最终的相似节点列表。

通过调整 `alpha` 和 `beta` 的值，可以根据不同任务需求，调节图结构和文本语义信息的重要性。
